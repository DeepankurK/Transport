{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f7c134c8acd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from .compat import (STRING_TYPES, DataFrame, py_str, PANDAS_INSTALLED,\n\u001b[0m\u001b[1;32m     24\u001b[0m                      lazy_isinstance)\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlibpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_lib_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from .utils._tags import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaskedArray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_MaskedArray\u001b[0m  \u001b[0;31m# TODO: remove in 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \"\"\"\n\u001b[0;32m--> 391\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeasurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m from scipy._lib._util import (_lazywhere, check_random_state, MapWrapper,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/spatial/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mckdtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqhull\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_spherical_voronoi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSphericalVoronoi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_plotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_procrustes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocrustes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/spatial/_spherical_voronoi.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_voronoi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcKDTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=pd.read_csv(\"x_m1.csv\")\n",
    "x_test1=pd.read_csv(\"x_test.csv\")\n",
    "y1=pd.read_csv(\"y_m1.csv\")\n",
    "y_test1=pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XM1=pd.read_csv(\"Data - M1.csv\")\n",
    "YM1=XM1.TAXI_OUT\n",
    "XM1=XM1.drop([\"TAXI_OUT\",\"cond\"],axis=1)\n",
    "XM2=pd.read_csv(\"Data - M2.csv\")\n",
    "YM2=XM2.j_del\n",
    "XM2=XM2.drop([\"arr_del\",\"j_del\",\"cond\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_basis addition\n",
    "category_list=['wind']\n",
    "#cat_var=['MONTH','DAY_OF_WEEK','OP_UNIQUE_CARRIER',]\n",
    "cat_var=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(a):\n",
    "    if a>=20:\n",
    "        a=a+1\n",
    "    if a>=10:\n",
    "        a=a+2\n",
    "    return a\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "for s in category_list:\n",
    "    XM1[s] = lb_make.fit_transform(XM1[s])\n",
    "    print(lb_make.transform(lb_make.classes_))\n",
    "    print(lb_make.classes_)\n",
    "    XM2[s] = lb_make.fit_transform(XM2[s])\n",
    "    print(lb_make.transform(lb_make.classes_))\n",
    "    print(lb_make.classes_)\n",
    "\n",
    "print(XM1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XM1.head(4),XM2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XM3=XM2[YM2>=0]\n",
    "YM3=YM2[YM2>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=XM3.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v(a):\n",
    "    if a<5:return 0\n",
    "    elif a<10: return 1\n",
    "    elif a<15: return 2\n",
    "    elif a<20: return 3\n",
    "    elif a<30: return 4\n",
    "    else: return 5\n",
    "def v2(a):\n",
    "    if a<0: return 0\n",
    "    else: return 1\n",
    "YM3=YM3.apply(v)\n",
    "YM2=YM2.apply(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "lgbm = LGBMRegressor()\n",
    "model1= lgb.Booster(model_file=r'./taxi_light.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "modelt=model1\n",
    "modelt.params[\"objective\"] = \"regression\"\n",
    "explainer1= shap.TreeExplainer(modelt)\n",
    "modelt.attr('objective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer1.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=model1.predict(XM1)\n",
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(YM1,pred1),\"mae\")\n",
    "from sklearn.metrics import median_absolute_error\n",
    "print(median_absolute_error(YM1,pred1),\"med a e\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.read_csv(\"x_train3.csv\")\n",
    "x_test=pd.read_csv(\"x_test3.csv\")\n",
    "y_train=pd.read_csv(\"y_train3.csv\")\n",
    "y_test=pd.read_csv(\"y_test3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "lgbm = LGBMClassifier()\n",
    "model3= lgb.Booster(model_file=r'./arr_light_all_class.txt')\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2= lgb.Booster(model_file=r'./arr_light_one_class.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "res=[np.round(i) for i in model2.predict(XM2)]\n",
    "print(np.array(np.unique(res, return_counts=True)).T)\n",
    "#print(y_test_m2)\n",
    "print(classification_report(YM2,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "res=[np.argmax(i) for i in model3.predict(XM3)]\n",
    "print(res)\n",
    "print(np.array(np.unique(res, return_counts=True)).T)\n",
    "#print(y_test_m2)\n",
    "print(classification_report(YM3,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YM3.head(65).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to our way of checking\n",
    "cls=[0]*len(YM3)\n",
    "cls2=[0]*len(YM3)\n",
    "for i in range(0,len(YM3)):\n",
    "    if not (YM3.iloc[i]+1>=res[i] and YM3.iloc[i]-1<=res[i]):\n",
    "        cls2[i]=1\n",
    "print(classification_report(cls2,cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "np.count_nonzero(np.round(model2.predict(XM2))==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "143/177 delay flights at M2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.params[\"objective\"] = \"regression\"\n",
    "explainer1 = shap.TreeExplainer(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer3 = shap.TreeExplainer(model3)\n",
    "DEP=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space=[]\n",
    "space.append(skopt.space.space.Integer(-20, 40, name='dep_delay'))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model(**params):\n",
    "    global cnt,x_t,x_t2,t\n",
    "    print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    cnt=cnt+1\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=params['dep_delay']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob=temp_t/np.sum(temp_t)\n",
    "    t=min(np.argmax(prob),t)\n",
    "    print(prob,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return np.sum([(t-i+1)*(1-prob[i]) for i in range(0,t+1)])+np.sum([(i+1)*(prob[i]) for i in range(t+1,6)])#+0.01*(params['dep_delay']+20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "space=[]\n",
    "space.append(Integer(-20, 30, name='dep_delay'))\n",
    "z=15\n",
    "cnt=1\n",
    "k=ind[z] #limit is [0-176]\n",
    "x_t=XM1.iloc[k:k+2,:].copy(deep=True)\n",
    "x_t.iloc[1,:]=XM1.iloc[k,:]\n",
    "print(x_t.iloc[0,:])\n",
    "print(\"out\",model1.predict(x_t.iloc[0,:]))\n",
    "print(\"Actual\",YM1.iloc[k])\n",
    "print(model2.predict(XM2.iloc[k,:]))\n",
    "x_t2=XM3.iloc[z:z+2,:].copy(deep=True)\n",
    "x_t2.iloc[1,:]=XM3.iloc[z,:]\n",
    "value2 = explainer3.shap_values(x_t2)\n",
    "sum_t=[i[0].sum() for i in value2]\n",
    "#print(sum_t)\n",
    "temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "prob=temp_t/np.sum(temp_t)\n",
    "t=np.argmax(prob)\n",
    "print(prob)\n",
    "print(t)\n",
    "print(YM3.iloc[z])\n",
    "\n",
    "t=np.argmax(prob)\n",
    "result = gp_minimize(evaluate_model,space,n_initial_points=5,n_calls=20)\n",
    "print('Best dep_delay: %s' % (result.x))\n",
    "params={(result.x)[0]}\n",
    "print(prob)\n",
    "res=evaluate_model(params)\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(result)\n",
    "from skopt.plots import plot_objective\n",
    "plot_objective(result, n_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model2(**params):\n",
    "    global cnt,x_t,x_t2,t\n",
    "    print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    cnt=cnt+1\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=x_temp.loc[1,'dep_del']+params['dep_delay']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob2=temp_t/np.sum(temp_t)\n",
    "    t=min(np.argmax(prob2),t)\n",
    "    print(prob2,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return np.sum([(t-i+1)*(1-prob2[i]) for i in range(0,t+1)])+np.sum([(i+1)*(prob2[i]) for i in range(t+1,6)])+0.005*(abs(params['dep_delay']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "space=[]\n",
    "space.append(Integer(-20, 20, name='dep_delay'))\n",
    "cnt=1\n",
    "k=ind[z] #limit is [0-176]\n",
    "DEP=XM1.iloc[k,5]\n",
    "x_t=XM1.iloc[k:k+2,:].copy(deep=True)\n",
    "x_t.iloc[1,:]=XM1.iloc[k,:]\n",
    "print(x_t.iloc[0,:])\n",
    "print(\"out\",model1.predict(x_t.iloc[0,:]))\n",
    "print(\"Actual\",YM1.iloc[k])\n",
    "print(model2.predict(XM2.iloc[k,:]))\n",
    "x_t2=XM3.iloc[z:z+2,:].copy(deep=True)\n",
    "x_t2.iloc[1,:]=XM3.iloc[z,:]\n",
    "value2 = explainer3.shap_values(x_t2)\n",
    "sum_t=[i[0].sum() for i in value2]\n",
    "#print(sum_t)\n",
    "temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "prob=temp_t/np.sum(temp_t)\n",
    "t=np.argmax(prob)\n",
    "print(prob)\n",
    "print(t)\n",
    "print(YM3.iloc[z])\n",
    "\n",
    "t=np.argmax(prob)\n",
    "result = gp_minimize(evaluate_model2,space,n_initial_points=5,n_calls=20)\n",
    "print('Best dep_delay: %s' % (result.x))\n",
    "params={(result.x)[0]}\n",
    "print(prob)\n",
    "res=evaluate_model2(params)\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(result)\n",
    "from skopt.plots import plot_objective\n",
    "plot_objective(result, n_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model22(**params):\n",
    "    global cnt,x_t,x_t2,t\n",
    "    print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    cnt=cnt+1\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=params['dep_delay']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob2=temp_t/np.sum(temp_t)\n",
    "    t=min(np.argmax(prob2),t)\n",
    "    print(prob2,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return np.sum([(t-i+1)*(1-prob2[i]) for i in range(0,t+1)])+np.sum([(i+1)*(prob2[i]) for i in range(t+1,6)])+0.005*(abs(params['dep_delay']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "space=[]\n",
    "space.append(Integer(-20, 30, name='dep_delay'))\n",
    "cnt=1\n",
    "k=ind[z] #limit is [0-176]\n",
    "x_t=XM1.iloc[k:k+2,:].copy(deep=True)\n",
    "x_t.iloc[1,:]=XM1.iloc[k,:]\n",
    "print(x_t.iloc[0,:])\n",
    "print(\"out\",model1.predict(x_t.iloc[0,:]))\n",
    "print(\"Actual\",YM1.iloc[k])\n",
    "print(model2.predict(XM2.iloc[k,:]))\n",
    "x_t2=XM3.iloc[z:z+2,:].copy(deep=True)\n",
    "x_t2.iloc[1,:]=XM3.iloc[z,:]\n",
    "value2 = explainer3.shap_values(x_t2)\n",
    "sum_t=[i[0].sum() for i in value2]\n",
    "#print(sum_t)\n",
    "temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "prob=temp_t/np.sum(temp_t)\n",
    "t=np.argmax(prob)\n",
    "print(prob)\n",
    "print(t)\n",
    "print(YM3.iloc[z])\n",
    "\n",
    "t=np.argmax(prob)\n",
    "result = gp_minimize(evaluate_model22,space,n_initial_points=5,n_calls=20)\n",
    "print('Best dep_delay: %s' % (result.x))\n",
    "params={(result.x)[0]}\n",
    "print(prob)\n",
    "res=evaluate_model2(params)\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(result)\n",
    "from skopt.plots import plot_objective\n",
    "plot_objective(result, n_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model3(**params):\n",
    "    global cnt,x_t,x_t2,tp\n",
    "    #print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    cnt=cnt+1\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=params['dep_delay']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob3=temp_t/np.sum(temp_t)\n",
    "    #t=min(np.argmax(prob3),t)\n",
    "   # print(prob3,tp)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return 1-prob3[tp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.argmax(prob)\n",
    "print(prob,t)\n",
    "for tp in range(0,t+1):\n",
    "    result = gp_minimize(evaluate_model3,space,n_initial_points=5,n_calls=20)\n",
    "    print('\\nBest dep_delay: %s' % (result.x))\n",
    "    params={(result.x)[0]}\n",
    "    print(evaluate_model3(params),tp)\n",
    "    #plot_convergence(result)\n",
    "    plot_objective(result, n_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_point(dep_del):\n",
    "    global x_t,x_t2\n",
    "    #print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=dep_del\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob=temp_t/np.sum(temp_t)\n",
    "    tp=np.argmax(prob)\n",
    "    #rint(prob,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    #print(pred[1])\n",
    "    return pred[1],tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model4(**params):\n",
    "    global x_t,x_t2,t\n",
    "    #print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=params['dep_delay']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob=temp_t/np.sum(temp_t)\n",
    "    t=min(np.argmax(prob),t)\n",
    "    #rint(prob,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return np.sum([(t-i+1)*(1-prob[i]) for i in range(0,t+1)])+np.sum([(i+1)*(prob[i]) for i in range(t+1,6)])#+0.01*(params['dep_delay']+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "time_list=[]\n",
    "import csv\n",
    "f=open(\"temp.csv\",\"w+\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "from tqdm import tqdm\n",
    "for z in tqdm(range(0,len(ind)-1)):\n",
    "    ls=[[]]\n",
    "    k=ind[z] #limit is [0-176]\n",
    "    x_t=XM1.iloc[k:k+2,:].copy(deep=True)\n",
    "    x_t.iloc[1,:]=XM1.iloc[k,:]\n",
    "    #print(x_t)\n",
    "    ls[0].append(x_t.iloc[0,5])\n",
    "    ls[0].append(YM1.iloc[k])\n",
    "    ls[0].append(YM3.iloc[z])\n",
    "    x_t2=XM3.iloc[z:z+2,:].copy(deep=True)\n",
    "    x_t2.iloc[1,:]=XM3.iloc[z,:]\n",
    "    value2 = explainer3.shap_values(x_t2)\n",
    "    sum_t=[i[0].sum() for i in value2]\n",
    "    #print(sum_t)\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob=temp_t/np.sum(temp_t)\n",
    "    tp=np.argmax(prob)\n",
    "    ls.append([x_t.iloc[0,5],model1.predict(XM1.iloc[k]),tp])\n",
    "    for num in [15,20,30,60]:    \n",
    "        space=[]\n",
    "        space.append(Integer(-20, 40, name='dep_delay'))\n",
    "        t=tp\n",
    "        result = gp_minimize(evaluate_model4,space,n_initial_points=5,n_calls=num)\n",
    "        tax,cl=eval_point((result.x)[0])\n",
    "        ls.append([(result.x)[0],tax,cl])\n",
    "    time_list.append(ls)\n",
    "    writer.writerows(ls)\n",
    "    print(len(time_list),len(ls),len(ls[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f=open(\"temp_2.csv\",\"w+\")\n",
    "writer = csv.writer(f)\n",
    "for i in time_list:\n",
    "    writer.writerows(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model51(**params):\n",
    "    global x_t,x_t2,t\n",
    "    #print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=params['dep_delay']+x_temp.loc[1,'dep_del']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob=temp_t/np.sum(temp_t)\n",
    "    t=min(np.argmax(prob),t)\n",
    "    #rint(prob,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return np.sum([(t-i+1)*(1-prob[i]) for i in range(0,t+1)])+np.sum([(i+1)*(prob[i]) for i in range(t+1,6)])+0.005*(abs(params['dep_delay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(space)\n",
    "def evaluate_model52(**params):\n",
    "    global x_t,x_t2,t\n",
    "    #print(\"Iter\",cnt,\"Dep_Del\",params['dep_delay'])\n",
    "    x_temp=x_t.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp2=x_t2.copy(deep=True).reset_index().drop(['index'],axis=1)\n",
    "    x_temp.loc[1,'dep_del']=params['dep_delay']\n",
    "    x_temp.loc[1,'act_dep_m']=x_temp.loc[1,'sch_dep_m']+x_temp.loc[1,'dep_del']\n",
    "    value1 = explainer1.shap_values(x_temp)\n",
    "    pred=value1.sum(axis=1)+explainer1.expected_value\n",
    "    #Here pred is taxi_out\n",
    "    x_temp2['taxi']=pred\n",
    "    x_temp2['dep_del']=x_temp['dep_del']\n",
    "    x_temp2['act_dep_m']=x_temp['act_dep_m']\n",
    "    x_temp2['wh_off']=x_temp2['act_dep_m']+x_temp2['taxi']\n",
    "    x_temp2['wh_on']=x_temp2['act_dep_m']+x_temp2['sch_elp']-13    \n",
    "    #print(x_temp)\n",
    "    value2 = explainer3.shap_values(x_temp2)\n",
    "    sum_t=[i[1].sum() for i in value2]\n",
    "    temp_t=[1/(1+np.exp(-sum_t[i]-explainer3.expected_value[i])) for i in range(0,6)]\n",
    "    prob=temp_t/np.sum(temp_t)\n",
    "    t=min(np.argmax(prob),t)\n",
    "    #rint(prob,t)\n",
    "    # new loss if want to atleast maximize the probability of one class \"metric\" i.e. mainitaining this class\n",
    "    # return 1-prob[t]\n",
    "    # reutn 1-prob[0] to maximize prob of that class\n",
    "    # current to shift distributoin towards left side.\n",
    "    # weighted probability does not give minimum\n",
    "    return np.sum([(t-i+1)*(1-prob[i]) for i in range(0,t+1)])+np.sum([(i+1)*(prob[i]) for i in range(t+1,6)])+0.005*(abs(params['dep_delay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "time_list2=[]\n",
    "from tqdm import tqdm\n",
    "for z in tqdm(range(0,len(ind)-1)):\n",
    "    ls=[[]]\n",
    "    k=ind.iloc[z] #limit is [0-176]\n",
    "    x_t=XM1.iloc[k:k+2,:].copy(deep=True)\n",
    "    x_t.iloc[1,:]=XM1.iloc[k,:]\n",
    "    #print(x_t)\n",
    "    ls[0].append(x_t.iloc[0,5])\n",
    "    ls[0].append(YM1.iloc[k])\n",
    "    ls[0].append(YM3.iloc[z])\n",
    "    \n",
    "    space=[]\n",
    "    space.append(Integer(-20, 20, name='dep_delay'))\n",
    "    t=tp\n",
    "    result = gp_minimize(evaluate_model51,space,n_initial_points=5,n_calls=20)\n",
    "    tax,cl=eval_point((result.x)[0]+x_t.iloc[1,'dep_del'])\n",
    "    ls.append([(result.x)[0],tax,cl])\n",
    "    \n",
    "    space=[]\n",
    "    space.append(Integer(-20, 40, name='dep_delay'))\n",
    "    t=tp\n",
    "    result = gp_minimize(evaluate_model52,space,n_initial_points=5,n_calls=20)\n",
    "    tax,cl=eval_point((result.x)[0])\n",
    "    ls.append([(result.x)[0],tax,cl])\n",
    "    \n",
    "    \n",
    "    time_list2.append(ls)\n",
    "len(time_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f=open(\"temp2.csv\",\"w+\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "for i in time_list2:\n",
    "    writer.writerows(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=pd.read_csv(\"temp.csv\",header=None)\n",
    "l2=pd.read_csv(\"temp2.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[0,1,2,3,4,5]\n",
    "y=['ori','15 min','20 min','30 min','60 min','pred']\n",
    "z=np.zeros(6,6)\n",
    "for i in range(0,len(l1),5):\n",
    "    z[l1.iloc[i,2]][0]+=1\n",
    "    z[l1.iloc[i+1,2]][1]+=1\n",
    "    z[l1.iloc[i+2,2]][2]+=1\n",
    "    z[l1.iloc[i+3,2]][3]+=1\n",
    "    z[l1.iloc[i+4,2]][4]+=1\n",
    "    z[np.argmax[model3.predict()]][5]+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    " \n",
    "# defining surface and axes\n",
    "x = np.outer(np.linspace(-2, 2, 10), np.ones(1))\n",
    "print(x)\n",
    "y = x.copy().T\n",
    "z = np.cos(x ** 2 + y ** 3)\n",
    "print(x.shape,y.shape,z.shape)\n",
    "fig = plt.figure()\n",
    " \n",
    "# syntax for 3-D plotting\n",
    "ax = plt.axes(projection ='3d')\n",
    " \n",
    "# syntax for plotting\n",
    "ax.plot_surface(x, y, z, cmap ='viridis', edgecolor ='green')\n",
    "ax.set_title('Surface plot geeks for geeks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# setup the figure and axes\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "# fake data\n",
    "_x = np.arange(4)\n",
    "_y = np.arange(5)\n",
    "_xx, _yy = np.meshgrid(_x, _y)\n",
    "x, y = _xx.ravel(), _yy.ravel()\n",
    "\n",
    "top = x + y\n",
    "bottom = np.zeros_like(top)\n",
    "width = depth = 1\n",
    "\n",
    "ax1.bar3d(x, y, bottom, width, depth, top, shade=True)\n",
    "ax1.set_title('Shaded')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.linspace(-6, 6, 30)\n",
    "y = np.linspace(-6, 6, 30)\n",
    "\n",
    "def z_function(x, y):\n",
    "    return np.sin(np.sqrt(x ** 2 + y ** 2))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = z_function(X, Y)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot_wireframe(X, Y, Z, color='green')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "# Normalize the colors based on Z value\n",
    "norm = plt.Normalize(Z2.min(), Z2.max())\n",
    "colors = cm.jet(norm(Z2))\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(X2, Y2, Z2, facecolors=colors, shade=False)\n",
    "surf.set_facecolor((0,0,0,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
